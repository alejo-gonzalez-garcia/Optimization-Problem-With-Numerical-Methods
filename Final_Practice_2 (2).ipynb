{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Alejo González García\" \n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second graded practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will have to handle a notebook with:\n",
    "\n",
    "* The working programs that solve the exercises. I will run all the codes.\n",
    "* An explanation of the methods you are using.\n",
    "* An explanation of your procedure to calculate the solutions.\n",
    "* An explanation of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal quadrature nodes and weights\n",
    "\n",
    "In this exercise we want to optimize the integration of polynomials using quadrature formulas:\n",
    "\n",
    "$$\\int_{-1}^{1} p_n(x) dx = \\sum_{i=1}^{M} \\omega_i p_n(x_i)$$\n",
    "\n",
    "Here $p_n(x)$ is a degree $n$ polynomial, $\\left\\{x_i \\right\\}$ are $M$ nodes inside the interval $[-1,1]$ and $\\omega_i$ are the weights of the quadrature formula.\n",
    "\n",
    "Let us suppose that you can use only two nodes, but you can choose which ones, and also you are free to choose the corresponding weights.\n",
    "\n",
    "Optimize the node positions and the value of the weights so your formula is exact for polynomials of the highest possible order.\n",
    "\n",
    "In order to do tackle this problem you need to code your own optimization method. \n",
    "\n",
    "The function you will have to minimize in this problem will not have an analytic expression, but no matter the method you choose, you will have to calculate the gradient. Think about finite differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sympy as sy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation of the path taken to solve the problem**\n",
    "\n",
    "The target on this assignment is to solve an optimization problem. I know we were provided many information about how to achieve the function to optimize but I am going to proof I understand it: \n",
    "\n",
    "We can manually solve this problem, in the analytic way. We know that with n equations we are going to be capable of integrating polynomials of order n-1, as for this practice we are using only 4 variables (x1, x2, w1, w2), we can integrate without computing error **up to degree $x^3$**. \n",
    "\n",
    "Also note that the integral we are computing is between bounds -1 and 1 meaning that if we integrate any polynomial with odd degree, the resulting integral will be zero, so we have to avoid been confused by this fact. \n",
    "\n",
    "To find the equation that we have to optimize we have to take each of the equations that we obtain when using the approximations to integrate 1, x, $x^2$ and $x^3$; and compute the error with respect to the real value of the integral. \n",
    "\n",
    "The square of each of this substractions is the formula we have to optimize. A very important fact, is that we need to compute the square of each equation, so that we obtain the optimal correct points, otherwise we will optimize the function and get really low error but the points will not work in reality. \n",
    "\n",
    "So, if we compute by Trapezoid Rule (will see it below) the integrals and then substract and elevate to the square each of the terms, we will get: \n",
    "\n",
    "Error(x1, x2, w1, w2) = $(2 - $w1$ - $w2$)^2$ + $($w1$ * $x1$ + $w2$ * $x2$)^2$ + $($2/3$ - $w1$ * $(x1^2)$ - w2 * $x2^2$)^2$+\n",
    "$($w1$ * $x1^3$ + $w2$ * $x2^3$)^2$\n",
    "\n",
    "Once we have the function defined, we need to optimize it, to do so we are going to use the next steps:\n",
    "\n",
    "  1. Implement **Composite Trapezoid Rule** to compute the Real value of each of the integrals and check our results.\n",
    "  2. Create a method to **compute the gradient** of a function with 4 variables by using finite differences.\n",
    "  3. Use a method to optimize the function, I have chosen **Gradient Descent** but any other is fine too.\n",
    "  \n",
    "Now that I have explained what is the approach we are going to follow, I am going to show the code followed to solve the practice and explain how I computed each of the steps. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compositeTrapezoid(f,a, b, n):\n",
    "\n",
    "        # f is the function that we want to integrate.\n",
    "        # a is the minimum value the integral can take\n",
    "        # b is the maximum possible value\n",
    "        # n is the number of points we consider\n",
    "                \n",
    "        H = (b-a) / (n)\n",
    "        currentPlusNextValue = 0\n",
    "        \n",
    "        for k in range(0, n): \n",
    "                currentPlusNextValue +=  f[k] + f[k+1] \n",
    "        \n",
    "        return currentPlusNextValue * (H / 2) \n",
    "    \n",
    "# Composite Trapezoid Rule Explanation: \n",
    "    # I have taken this method from the first practice, it allows me to compute the value of any integral with\n",
    "    # a high precision so that we can take it as the real value. \n",
    "    \n",
    "    # What it does is multiplying the step size times the sum of the values of the function \n",
    "    # at time, k, plus the next time value.\n",
    "    # At the end it gives the value of the integral in the provided bounds. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAListOfIntegrals(lowerBound, upperBound, functionsToIntegrate, n):\n",
    "    \n",
    "    solutionsOfTheIntegrals = []\n",
    "\n",
    "    for i in range(0, len(functionsToIntegrate)):\n",
    "        f = functionsToIntegrate[i]\n",
    "        solutionsOfTheIntegrals.append(compositeTrapezoid(f, lowerBound, upperBound, n))   \n",
    "    return solutionsOfTheIntegrals\n",
    "\n",
    "# ComputeAListOfIntegrals Explanation:\n",
    "    # This is a method that I have implemented so that we can compute the integrals of many functions. \n",
    "    # It computes each of the integrals with Trapezoid rule (method above) and plugs them in a list.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeGradientInFourVariables(x, y, z, w, f, h):\n",
    "    \n",
    "        # f: function from which I am computing the gradient. \n",
    "        # h: step size I take. In general the smaller the better, but so small implies so slow. \n",
    "        # partial X, Y, Z, W: Partial Derivative with respect to X, Y, Z, W.\n",
    "\n",
    "    partialX = ((f(x+h, y, z, w) - f(x-h, y, z, w)) / (2*h))\n",
    "    partialY = ((f(x, y+h, z, w) - f(x, y-h, z, w)) / (2*h))\n",
    "    partialZ = ((f(x, y, z+h, w) - f(x, y, z-h, w)) / (2*h)) \n",
    "    partialW = ((f(x, y, z, w+h) - f(x, y, z, w-h)) / (2*h))\n",
    "\n",
    "    return np.array([partialX, partialY, partialZ, partialW], dtype=object)\n",
    "\n",
    "# ComputeGradientInFourVariables Explanation: \n",
    "    \n",
    "    # This method is as simpler as it seems to be. \n",
    "    # If we apply finite differences in the multivariate case, the only difference with one variable case is \n",
    "    # that we only need to sum and substract the step size on the variable we are computting the derivate at. \n",
    "    \n",
    "    # After computing each of the partial derivatives, we plug them all togheter on an array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ErrorFunction(x1, x2, w1, w2):\n",
    "    return ((2 - w1 - w2)**2 + (w1*x1 + w2*x2)**2 + ((2/3) - w1*(x1**2) - w2*(x2**2))**2 + (w1*(x1**3) + w2*(x2**3))**2)\n",
    "    \n",
    "# ErrorFunction Explanation: \n",
    "    # This function is the error function, the one we defined previously in the statement, the one we are going \n",
    "    # to optimize. It depends on the 4 possible variables. \n",
    "    \n",
    "    # Remark that values 2 and 2/3 have been computed with Trapezoid Rule but\n",
    "    # it is an easy integral that takes few time by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescend(f, initialTimePoints, alpha, tol):\n",
    "    \n",
    "    # f is the function we are optimizing.\n",
    "    # initialTimePoints is the set of 4 initial points from which we start to find the minimum of the function. \n",
    "    # alpha is a tricky value, the one that reduces the step size at each iteration and we will deal with. \n",
    "    # tol is the stopping criteria, the error we tolerate to have. \n",
    "    \n",
    "    \n",
    "    t = initialTimePoints.copy() # We are storing the initial points in a variable for further use. \n",
    "    \n",
    "    previousInitTimePoints = initialTimePoints - 10 * tol # Obtain the previous points, to the assigned ones this\n",
    "                                                          # selection depends a lot on the tolerance we select. \n",
    "    \n",
    "    maxIterationsAllowed = 5000 # Number of maximum iterations I allow to use (We will not use more than 2000).\n",
    "    iterationCount = 0 # Iteration number at which we are located. \n",
    "    initialAlphaProvided = alpha # Storing the initial value of alpha so that I can reset it whenever I need it. \n",
    "\n",
    "    resetAlphaWhenAchieved = 3 # I will reset the value of alpha each 3 iterations, so that the step size is not so small. \n",
    "                               # If I decrease this number up to 2, depending on the initial points, the number of iterations \n",
    "                               # is reduced. \n",
    "            \n",
    "    resetAlphaCounter = 0 # Iteration number (between 0 and resetValue) at which alpha is located. \n",
    "    \n",
    "    while np.linalg.norm(t - previousInitTimePoints) > tol and iterationCount < maxIterationsAllowed:\n",
    "        # If have not achieved the desired accuracy and the max number of iterations is not achieved, I do not stop.  \n",
    "\n",
    "        previousInitTimePoints = t.copy()\n",
    "        t = t -  (alpha * computeGradientInFourVariables(t[0], t[1], t[2], t[3], f, h = 0.00001))\n",
    "        \n",
    "        # This is the key point, I substract to the current point t, alpha times the gradient of the function \n",
    "        # at points 0, 1, 2 and 3 of my current point. \n",
    "        # In this way I keep reducing the distance to the minimum in a descent direction continuosly. \n",
    "        \n",
    "        iterationCount += 1 # Increase iteration count at which we are. \n",
    "        alpha =  (1/2) * alpha # Decrease the value of alpha\n",
    "        resetAlphaCounter += 1 # Increase iteration at which alpha is. \n",
    "\n",
    "        print(ErrorFunction(t[0], t[1], t[2], t[3])) # This shows how are we doing progress in each of the iterations. \n",
    "\n",
    "        if resetAlphaWhenAchieved == resetAlphaCounter: # When the reset value of alpha is achieved.\n",
    "\n",
    "            alpha = initialAlphaProvided # Reset alpha to original value.\n",
    "            resetAlphaCounter = 0 # Set reset of alpha to 0 again.\n",
    "    \n",
    "    return t, iterationCount # Return the minimum and the number of iterations we computed. \n",
    "\n",
    "# Gradient Descend Method Explained: \n",
    "    # I have explained at each step what is the method doing so maybe it seems a bit long. \n",
    "    # What we are doing at the end is computing the gradient at the given points and at each step \n",
    "    # we make sure about we are decreasing into the good direction and we are getting closer to the minimum. \n",
    "    \n",
    "    # All the alpha related stuff could be removed and the method keeps working if we just set alpha to 1/2, \n",
    "    # but I think that reseting the value each N steps is a good improvement for the method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimation(x, w0, w1, pn):\n",
    "    return(w0 * pn(x[0]) + w1 * pn(x[1]))\n",
    "\n",
    "# Estimation Explanation:\n",
    "    # This method is the approximation that we must fulfill at the end, as said by the statement of the problem.\n",
    "    # It multiplies each of the weights by the value of the polynomial we want to approximate at the correspoing point x. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0661384068393223\n",
      "0.987601734138661\n",
      "0.7354015108577316\n",
      "0.2506290250075848\n",
      "0.18108071425498445\n",
      "0.15089697708792887\n",
      "0.060131234395041894\n",
      "0.04389967756983592\n",
      "0.03962575940098741\n",
      "0.030210913473111348\n",
      "0.028286739842355427\n",
      "0.027480077260407347\n",
      "0.024586779738700482\n",
      "0.02335063364151406\n",
      "0.022763255594079036\n",
      "0.02052225658723232\n",
      "0.01950052089393893\n",
      "0.019011719022423615\n",
      "0.017140588565798778\n",
      "0.01628493629021195\n",
      "0.01587556524510398\n",
      "0.014308659076091673\n",
      "0.013592406603872297\n",
      "0.01324981197914303\n",
      "0.01193880558969185\n",
      "0.011339808196451945\n",
      "0.011053359683790454\n",
      "0.009957426036997018\n",
      "0.009456891018574609\n",
      "0.00921757074593034\n",
      "0.008302097323828611\n",
      "0.007884117024228688\n",
      "0.007684297625827331\n",
      "0.006920030916716249\n",
      "0.006571180429776706\n",
      "0.006404429226530608\n",
      "0.005766712885711153\n",
      "0.005475690561581524\n",
      "0.00533659515739212\n",
      "0.0048046938856182685\n",
      "0.00456200458135657\n",
      "0.004446019703206504\n",
      "0.00400252726571045\n",
      "0.003800206597196737\n",
      "0.003703521093600605\n",
      "0.0033338474212261794\n",
      "0.003165223888732248\n",
      "0.0030846462145269083\n",
      "0.002776576565230409\n",
      "0.0026360677851219837\n",
      "0.0025689280506465246\n",
      "0.0023122464509514667\n",
      "0.002195185557087612\n",
      "0.002139252177221762\n",
      "0.0019254213357800332\n",
      "0.0018279097229315128\n",
      "0.0017813187795374576\n",
      "0.0016032090559761824\n",
      "0.0015219918992387094\n",
      "0.0014831874735039114\n",
      "0.0013348480961024299\n",
      "0.0012672094157925471\n",
      "0.0012348933196384667\n",
      "0.0011113597493226665\n",
      "0.0010550341512970815\n",
      "0.0010281236677143679\n",
      "0.0009252557269409873\n",
      "0.0008783543042012363\n",
      "0.0008559467223017313\n",
      "0.0007702928007788698\n",
      "0.0007312410171445387\n",
      "0.0007125839117641667\n",
      "0.0006412672025034569\n",
      "0.0006087528845671365\n",
      "0.0005932192389754748\n",
      "0.0005338425366065093\n",
      "0.0005067723728507899\n",
      "0.0004938397753272128\n",
      "0.0004444058808672735\n",
      "0.00042186906655989465\n",
      "0.00041110232745084194\n",
      "0.00036994755134746874\n",
      "0.0003511854261704421\n",
      "0.0003422220625118635\n",
      "0.00030796070509042856\n",
      "0.0002923414099999205\n",
      "0.000284879531192831\n",
      "0.00025635755221767705\n",
      "0.00024335488569302233\n",
      "0.00023714308757552348\n",
      "0.000213399460503128\n",
      "0.000202575245169726\n",
      "0.0001974041826357748\n",
      "0.00017763867031050397\n",
      "0.00016862805185375408\n",
      "0.00016432341337463033\n",
      "0.00014786970604036134\n",
      "0.00014036890005494782\n",
      "0.00013678555238333715\n",
      "0.00012308888112886357\n",
      "0.00011684496254630645\n",
      "0.00011386207172585323\n",
      "0.00010246055548746212\n",
      "9.72629516498866e-05\n",
      "9.477991825358096e-05\n",
      "8.528902430562758e-05\n",
      "8.096242851020387e-05\n",
      "7.889550171936763e-05\n",
      "7.099510176598992e-05\n",
      "6.739357084045494e-05\n",
      "6.567302833430291e-05\n",
      "5.909661789915166e-05\n",
      "5.609865649451338e-05\n",
      "5.4666455836416215e-05\n",
      "4.919217626627634e-05\n",
      "4.669664327378026e-05\n",
      "4.550446612751847e-05\n",
      "4.094762839465742e-05\n",
      "3.887032823957304e-05\n",
      "3.7877951824232296e-05\n",
      "3.408481132713818e-05\n",
      "3.235565572840424e-05\n",
      "3.1529596837296174e-05\n",
      "2.8372170156657758e-05\n",
      "2.693281500037605e-05\n",
      "2.6245201020135796e-05\n",
      "2.3616950429141332e-05\n",
      "2.2418828305819944e-05\n",
      "2.1846457272101857e-05\n",
      "1.9658697863358844e-05\n",
      "1.866138007919932e-05\n",
      "1.8184938142710327e-05\n",
      "1.6363846666991446e-05\n",
      "1.5533679594426122e-05\n",
      "1.5137089554223477e-05\n",
      "1.362121426622427e-05\n",
      "1.2930184113452631e-05\n",
      "1.2600063077462143e-05\n",
      "1.1338250717782133e-05\n",
      "1.076303847471854e-05\n",
      "1.0488246376205579e-05\n",
      "9.437916444807379e-06\n",
      "8.959111159884635e-06\n",
      "8.730374915174335e-06\n",
      "7.856083076958718e-06\n",
      "7.457526947676115e-06\n",
      "7.26712758641454e-06\n",
      "6.539369782144147e-06\n",
      "6.2076129805936944e-06\n",
      "6.04912520031696e-06\n",
      "5.4433421426428445e-06\n",
      "5.1671889934804486e-06\n",
      "5.035264356326895e-06\n",
      "4.53101284135084e-06\n",
      "4.301144047734621e-06\n",
      "4.1913305076761904e-06\n",
      "3.7715935940079857e-06\n",
      "3.580251770034095e-06\n",
      "3.488843443550691e-06\n",
      "3.1394562316451663e-06\n",
      "2.9801841340175413e-06\n",
      "2.904096246706852e-06\n",
      "2.6132678886011143e-06\n",
      "2.480690517071631e-06\n",
      "2.4173553075970745e-06\n",
      "2.1752711220014436e-06\n",
      "2.0649143374702644e-06\n",
      "2.012194406972237e-06\n",
      "1.8106846762369932e-06\n",
      "1.7188242170245966e-06\n",
      "1.674940400545974e-06\n",
      "1.50720467499231e-06\n",
      "1.4307404771270269e-06\n",
      "1.394211803407963e-06\n",
      "1.2545894109694366e-06\n",
      "1.1909409919169094e-06\n",
      "1.1605347057234931e-06\n",
      "1.0443137234544893e-06\n",
      "9.913330992917588e-07\n",
      "9.660230599062326e-07\n",
      "8.692813015688988e-07\n",
      "8.251804991526129e-07\n",
      "8.041125512452215e-07\n",
      "7.235852052963927e-07\n",
      "6.868759233949144e-07\n",
      "6.693390717473319e-07\n",
      "6.023085232676019e-07\n",
      "5.717519065462469e-07\n",
      "5.571543219251151e-07\n",
      "5.013584405359794e-07\n",
      "4.759232715048201e-07\n",
      "4.637723179953769e-07\n",
      "4.1732811691088837e-07\n",
      "3.961560149995263e-07\n",
      "3.8604162480517533e-07\n",
      "3.4738171481406653e-07\n",
      "3.2975816817846755e-07\n",
      "3.2133900285409087e-07\n",
      "2.891586968127063e-07\n",
      "2.744889493047882e-07\n",
      "2.674808804129349e-07\n",
      "2.4069416320324903e-07\n",
      "2.284831427717906e-07\n",
      "2.2264966322260814e-07\n",
      "2.0035254131042458e-07\n",
      "1.9018815247947762e-07\n",
      "1.8533239496831275e-07\n",
      "1.6677238872304282e-07\n",
      "1.5831160531911214e-07\n",
      "1.5426969850765152e-07\n",
      "1.3882044773780884e-07\n",
      "1.3177773653795039e-07\n",
      "1.2841327476834363e-07\n",
      "1.1555340048191143e-07\n",
      "1.0969108510952511e-07\n",
      "1.0689052501916711e-07\n",
      "9.61860340500406e-08\n",
      "9.130627392623793e-08\n",
      "8.897510261201364e-08\n",
      "8.006474131325814e-08\n",
      "7.600285497497579e-08\n",
      "7.406240039093759e-08\n",
      "6.664546311994913e-08\n",
      "6.326437058175353e-08\n",
      "6.16491465304482e-08\n",
      "5.547532749156835e-08\n",
      "5.266092409579797e-08\n",
      "5.1316420211486845e-08\n",
      "4.6177366180691234e-08\n",
      "4.383467181276898e-08\n",
      "4.2715513955078766e-08\n",
      "3.843779281011018e-08\n",
      "3.648774652539075e-08\n",
      "3.5556165500183114e-08\n",
      "3.1995413261385625e-08\n",
      "3.037220514879235e-08\n",
      "2.9596762079209833e-08\n",
      "2.6632810935922666e-08\n",
      "2.5281661174952047e-08\n",
      "2.4636186506886985e-08\n",
      "2.216900941212015e-08\n",
      "2.1044319571436172e-08\n",
      "2.0507029907278644e-08\n",
      "1.845336487930858e-08\n",
      "1.7517179067415678e-08\n",
      "1.7069942022917087e-08\n",
      "1.536048223151364e-08\n",
      "1.4581206166521601e-08\n",
      "1.4208928441682553e-08\n",
      "1.2785983250770335e-08\n",
      "1.2137318020884349e-08\n",
      "1.1827436033298275e-08\n",
      "1.0642984065063386e-08\n",
      "1.0103038596400987e-08\n",
      "9.845094487048335e-09\n",
      "8.859163002808062e-09\n",
      "8.409715282344218e-09\n",
      "8.195003985235957e-09\n",
      "7.374319890756053e-09\n",
      "7.000202012103408e-09\n",
      "6.821477476795865e-09\n",
      "6.1383444261132076e-09\n",
      "5.8269307050189805e-09\n",
      "5.6781613578181205e-09\n",
      "5.109525060509648e-09\n",
      "4.850305944879138e-09\n",
      "4.726471136066982e-09\n",
      "4.253141324005357e-09\n",
      "4.037368718825236e-09\n",
      "3.934289286431606e-09\n",
      "3.540292082977562e-09\n",
      "3.360684120735266e-09\n",
      "3.2748813526549087e-09\n",
      "2.946920188288852e-09\n",
      "2.7974154813924905e-09\n",
      "2.7259937162706997e-09\n",
      "2.4530005976219317e-09\n",
      "2.328553679452503e-09\n",
      "2.2691025842816393e-09\n",
      "2.0418645728501605e-09\n",
      "1.938275623973252e-09\n",
      "1.8887888504201727e-09\n",
      "1.6996371454719323e-09\n",
      "1.6134102586447709e-09\n",
      "1.5722177331129114e-09\n",
      "1.4147688659240624e-09\n",
      "1.3429940666808223e-09\n",
      "1.3087056288189783e-09\n",
      "1.1776460341871139e-09\n",
      "1.11790107531495e-09\n",
      "1.0893595630976005e-09\n",
      "9.80266257742312e-10\n",
      "9.305348736439817e-10\n",
      "9.067770715820198e-10\n",
      "8.159683879137096e-10\n",
      "7.745722498767206e-10\n",
      "7.547963825558067e-10\n",
      "6.792077201448252e-10\n",
      "6.447497963318983e-10\n",
      "6.282884701899094e-10\n",
      "5.653688720385182e-10\n",
      "5.366862806316019e-10\n",
      "5.229839608262685e-10\n",
      "4.706100239839911e-10\n",
      "4.467347883634597e-10\n",
      "4.353290506757994e-10\n",
      "3.9173326588230333e-10\n",
      "3.718596474971049e-10\n",
      "3.6236557247657966e-10\n",
      "3.2607667447787253e-10\n",
      "3.095339808726406e-10\n",
      "3.016311636241869e-10\n",
      "2.714244791027037e-10\n",
      "2.5765442946008734e-10\n",
      "2.510761666694167e-10\n",
      "2.2593228409997733e-10\n",
      "2.1447016845555895e-10\n",
      "2.0899445770133754e-10\n",
      "1.880648243890062e-10\n",
      "1.7852382066018882e-10\n",
      "1.7396586832800827e-10\n",
      "1.5654415354723656e-10\n",
      "1.486022730945453e-10\n",
      "1.4480825796248131e-10\n",
      "1.3030651579740798e-10\n",
      "1.2369573700203808e-10\n",
      "1.2053761910764787e-10\n",
      "1.0846644652300644e-10\n",
      "1.0296366962756834e-10\n",
      "1.0033486919009817e-10\n",
      "9.028688972273857e-11\n",
      "8.570640767686598e-11\n",
      "8.351820825886445e-11\n",
      "7.51543239134795e-11\n",
      "7.13415551681246e-11\n",
      "6.952010968211695e-11\n",
      "6.255805710490961e-11\n",
      "5.938432880263922e-11\n",
      "5.7868167324182665e-11\n",
      "5.207299201243955e-11\n",
      "4.9431197554838495e-11\n",
      "4.816915285412288e-11\n",
      "4.334527993259556e-11\n",
      "4.1146264362410125e-11\n",
      "4.0095745105703015e-11\n",
      "3.608037909740372e-11\n",
      "3.424993030382953e-11\n",
      "3.337548369458442e-11\n",
      "3.003311451560316e-11\n",
      "2.850945873228901e-11\n",
      "2.7781574055015528e-11\n",
      "2.4999403833078396e-11\n",
      "2.3731120912655268e-11\n",
      "2.3125233601720552e-11\n",
      "2.080936999679226e-11\n",
      "1.9753658080618743e-11\n",
      "1.9249320725062885e-11\n",
      "1.7321608250752816e-11\n",
      "1.6442839300738076e-11\n",
      "1.6023031584217066e-11\n",
      "1.4418414035865147e-11\n",
      "1.3686931463277802e-11\n",
      "1.3337485767055694e-11\n",
      "1.2001810706014854e-11\n",
      "1.1392928526378246e-11\n",
      "1.1102051798210357e-11\n",
      "9.990243023936247e-12\n",
      "9.483412756135224e-12\n",
      "9.2412885236281e-12\n",
      "8.315824849251139e-12\n",
      "7.893942046377777e-12\n",
      "7.692399131062202e-12\n",
      "6.9220481201141124e-12\n",
      "6.570875132611811e-12\n",
      "6.403111887849584e-12\n",
      "5.761875828446587e-12\n",
      "5.469561312184434e-12\n",
      "5.32991608553115e-12\n",
      "4.796154620711752e-12\n",
      "4.552833581684916e-12\n",
      "4.436593642193928e-12\n",
      "3.992293455083439e-12\n",
      "3.7897543241242865e-12\n",
      "3.6929968202920615e-12\n",
      "3.323163721902009e-12\n",
      "3.1545712331138747e-12\n",
      "3.0740308047553378e-12\n",
      "2.76618371222519e-12\n",
      "2.6258482266193498e-12\n",
      "2.5588068050100826e-12\n",
      "2.3025565326828433e-12\n",
      "2.185742025180652e-12\n",
      "2.1299371044904817e-12\n",
      "1.9166357491342438e-12\n",
      "1.819399978038878e-12\n",
      "1.7729482607905152e-12\n",
      "1.5953973537886531e-12\n",
      "1.5144588182857824e-12\n",
      "1.4757926573520306e-12\n",
      "1.3280002322437962e-12\n",
      "1.26062742860426e-12\n",
      "1.228441923106184e-12\n",
      "1.1054202992609615e-12\n",
      "1.0493395378816986e-12\n",
      "1.0225484952812457e-12\n",
      "9.20145953914719e-13\n",
      "8.734646281366671e-13\n",
      "8.511639076183425e-13\n",
      "7.65924580142051e-13\n",
      "7.270672944756162e-13\n",
      "7.085042940536883e-13\n",
      "6.375515338520359e-13\n",
      "6.052069371756758e-13\n",
      "5.897551948508198e-13\n",
      "5.30694497036158e-13\n",
      "5.037710278322141e-13\n",
      "4.909090803317286e-13\n",
      "4.4174727132213765e-13\n",
      "4.193363196515701e-13\n",
      "4.086301033343055e-13\n",
      "3.677080766372613e-13\n",
      "3.4905332034117936e-13\n",
      "3.401415231458532e-13\n",
      "3.060782471509604e-13\n",
      "2.9055012775907783e-13\n",
      "2.8313199551395616e-13\n",
      "2.547779068105866e-13\n",
      "2.418523833202066e-13\n",
      "2.356775697795659e-13\n",
      "2.1207577799063644e-13\n",
      "2.0131664142362746e-13\n",
      "1.9617675961080572e-13\n",
      "1.7653075446872546e-13\n",
      "1.6757490671695948e-13\n",
      "1.6329649666436396e-13\n",
      "1.469432670857396e-13\n",
      "1.3948846735353237e-13\n",
      "1.3592714170756758e-13\n",
      "1.2231480095100212e-13\n",
      "1.1610946552367188e-13\n",
      "1.1314503708287344e-13\n",
      "1.0181419748329092e-13\n",
      "9.664890948103992e-14\n",
      "9.418133512248592e-14\n",
      "8.474960480861745e-14\n",
      "8.045004675844737e-14\n",
      "7.839605100938546e-14\n",
      "7.054512920729158e-14\n",
      "6.696620008765855e-14\n",
      "6.525646504966937e-14\n",
      "5.872139970904731e-14\n",
      "5.574231826924465e-14\n",
      "5.431914393961155e-14\n",
      "4.8879390570079886e-14\n",
      "4.639961910513595e-14\n",
      "4.5214976429295774e-14\n",
      "4.068695480312297e-14\n",
      "3.8622806308380966e-14\n",
      "3.763671607757403e-14\n",
      "3.3867615096814556e-14\n",
      "3.214942892700332e-14\n",
      "3.132861269656603e-14\n",
      "2.819123321763566e-14\n",
      "2.6761024244356664e-14\n",
      "2.6077781243804433e-14\n",
      "2.3466243352838753e-14\n",
      "2.2275745066679778e-14\n",
      "2.1707017193287753e-14\n",
      "1.9533187060247586e-14\n",
      "1.8542222620784932e-14\n",
      "1.8068816625648608e-14\n",
      "1.6259332018094404e-14\n",
      "1.5434458536778222e-14\n",
      "1.5040397910525502e-14\n",
      "1.3534192612266512e-14\n",
      "1.2847572331801397e-14\n",
      "1.2519558376473511e-14\n",
      "1.1265801147380107e-14\n",
      "1.0694262110255036e-14\n",
      "1.0421225042900933e-14\n",
      "9.37760422315772e-15\n",
      "8.901858209804842e-15\n",
      "8.67458359908378e-15\n",
      "7.805879218182809e-15\n",
      "7.409870765149911e-15\n",
      "7.220688628791533e-15\n",
      "6.4975837420496155e-15\n",
      "6.167948425280339e-15\n",
      "6.0104741972856614e-15\n",
      "5.408565579368173e-15\n",
      "5.134178890944724e-15\n",
      "5.003098210035469e-15\n",
      "4.502072671238655e-15\n",
      "4.273674677435177e-15\n",
      "4.164563817522732e-15\n",
      "3.747512852501641e-15\n",
      "3.557395577050581e-15\n",
      "3.4665722862143088e-15\n",
      "3.1194212911293903e-15\n",
      "2.9611686862784802e-15\n",
      "2.8855678535034477e-15\n",
      "2.5966012258946758e-15\n",
      "2.4648726065647124e-15\n",
      "2.4019428743117733e-15\n",
      "2.1614086074694774e-15\n",
      "2.0517584133074862e-15\n",
      "1.999376039694485e-15\n",
      "1.7991565943843363e-15\n",
      "1.707884353230803e-15\n",
      "1.664281546485734e-15\n",
      "1.4976199548308592e-15\n",
      "1.421645437550813e-15\n",
      "1.385350699201335e-15\n",
      "1.2466224731447422e-15\n",
      "1.183381684432285e-15\n",
      "1.1531701454194028e-15\n",
      "1.037693514378228e-15\n",
      "9.850522253891051e-16\n",
      "9.599042947907806e-16\n",
      "8.637821682893626e-16\n",
      "8.199638350170001e-16\n",
      "7.99030834400919e-16\n",
      "7.190192936203986e-16\n",
      "6.825451524392547e-16\n",
      "6.651206296539714e-16\n",
      "5.985194506668623e-16\n",
      "5.681585668559061e-16\n",
      "5.536544905303859e-16\n",
      "4.9821602611306515e-16\n",
      "4.729437915777896e-16\n",
      "4.608706761667134e-16\n",
      "4.147239938675583e-16\n",
      "3.9368752221666783e-16\n",
      "3.8363792595961013e-16\n",
      "3.452256758590702e-16\n",
      "3.277150244887527e-16\n",
      "3.193497977495623e-16\n",
      "2.873756459445596e-16\n",
      "2.7279987319125647e-16\n",
      "2.658366982941732e-16\n",
      "2.392215863080009e-16\n",
      "2.2708879376439985e-16\n",
      "2.2129268755548818e-16\n",
      "1.9913840726419136e-16\n",
      "1.890391355222956e-16\n",
      "1.8421448687337876e-16\n",
      "1.6577338662801782e-16\n",
      "1.5736680494197298e-16\n",
      "1.5335079336872348e-16\n",
      "1.3800051723926222e-16\n",
      "1.3100292589822188e-16\n",
      "1.2766001980202435e-16\n",
      "1.1488253126831599e-16\n",
      "1.0905777338132774e-16\n",
      "1.0627515694009819e-16\n",
      "9.563924356766984e-17\n",
      "9.079074535807962e-17\n",
      "8.847450993372219e-17\n",
      "7.962123471085785e-17\n",
      "7.558537069597432e-17\n",
      "7.365734766365179e-17\n",
      "6.62879281061813e-17\n",
      "6.292849762513377e-17\n",
      "6.132362160592841e-17\n",
      "5.518935600906473e-17\n",
      "5.239298341634602e-17\n",
      "5.1057092705956635e-17\n",
      "4.59509626649008e-17\n",
      "4.3623278022294386e-17\n",
      "4.251129014734124e-17\n",
      "3.826097545700221e-17\n",
      "3.632342290745701e-17\n",
      "3.539780976945568e-17\n",
      "3.1859870762821704e-17\n",
      "3.024706238026305e-17\n",
      "2.9476586889355615e-17\n",
      "2.653162565608576e-17\n",
      "2.5189132443418266e-17\n",
      "2.454779285265162e-17\n",
      "2.2096421947595804e-17\n",
      "2.0978937129083042e-17\n",
      "2.0445089943897264e-17\n",
      "1.840458291649712e-17\n",
      "1.747439506024587e-17\n",
      "1.703002305747919e-17\n",
      "1.5331515155693883e-17\n",
      "1.4557231688075466e-17\n",
      "1.4187339258946957e-17\n",
      "1.2773511017448318e-17\n",
      "1.2129001393141718e-17\n",
      "1.1821104143737588e-17\n",
      "1.0644240902692116e-17\n",
      "1.0107754919836516e-17\n",
      "9.851463468872595e-18\n",
      "8.871848880216604e-18\n",
      "8.425280622552499e-18\n",
      "8.211945089712297e-18\n",
      "7.396518909266621e-18\n",
      "7.024797971085799e-18\n",
      "6.847218288399384e-18\n",
      "6.168462251045501e-18\n",
      "5.859043884934933e-18\n",
      "5.711227430477753e-18\n",
      "5.146234128916256e-18\n",
      "4.888675541335745e-18\n",
      "4.765634409926754e-18\n",
      "4.29533697633092e-18\n",
      "4.080946773655113e-18\n",
      "3.978527548208319e-18\n",
      "3.587054774402453e-18\n",
      "3.4085974928425257e-18\n",
      "3.323344009296635e-18\n",
      "2.9974843307962348e-18\n",
      "2.848937429666132e-18\n",
      "2.7779732476227312e-18\n",
      "2.5067290370776824e-18\n",
      "2.3830794554089826e-18\n",
      "2.324009350093975e-18\n",
      "2.0982270850839496e-18\n",
      "1.9953017664864826e-18\n",
      "1.946132091617824e-18\n",
      "1.7581922180376086e-18\n",
      "1.6725178558557253e-18\n",
      "1.631589113057528e-18\n",
      "1.47514913582981e-18\n",
      "1.4038342478376707e-18\n",
      "1.3697654153778254e-18\n",
      "1.2395455196211851e-18\n",
      "1.1801832182442496e-18\n",
      "1.1518245779076833e-18\n",
      "1.0434302069646005e-18\n",
      "9.940175249664517e-19\n",
      "9.704118392966208e-19\n",
      "8.801850090349223e-19\n",
      "8.3905388357794985e-19\n",
      "8.194047131065078e-19\n",
      "7.443003925000306e-19\n",
      "7.100633013859067e-19\n",
      "6.937074042483251e-19\n",
      "6.311909911842151e-19\n",
      "6.026921593248403e-19\n",
      "5.890777631524428e-19\n",
      "5.370392208271557e-19\n",
      "5.1331699993073545e-19\n",
      "5.019842874265755e-19\n",
      "4.586678262080507e-19\n",
      "4.389216446515571e-19\n",
      "4.294883185660618e-19\n",
      "3.934319714707155e-19\n",
      "3.76995193249073e-19\n",
      "3.69143031218784e-19\n",
      "3.3912987382986105e-19\n",
      "3.2544805029740027e-19\n",
      "3.1891195024323956e-19\n",
      "2.939292398380475e-19\n",
      "2.825404552456237e-19\n",
      "2.7709984122495165e-19\n",
      "2.563043120294378e-19\n",
      "2.4682442043247125e-19\n",
      "2.4229570118374183e-19\n",
      "2.2498560637566834e-19\n",
      "2.1709456667651336e-19\n",
      "2.1332486979256146e-19\n",
      "1.9891594875900184e-19\n",
      "1.9234763904216957e-19\n",
      "1.8920972440992075e-19\n",
      "1.77215794588267e-19\n",
      "1.7174826971528296e-19\n",
      "1.691363500188974e-19\n",
      "1.591528186448612e-19\n",
      "1.54601683466101e-19\n",
      "1.5242754151650193e-19\n",
      "1.4411714095955378e-19\n",
      "1.4032878196890265e-19\n",
      "1.3851913263843593e-19\n",
      "1.3160170092720376e-19\n",
      "1.2844822517634148e-19\n",
      "1.2694181675006765e-19\n",
      "1.211838087325822e-19\n",
      "1.1855893732305e-19\n",
      "1.1730492660792895e-19\n",
      "1.125119250198074e-19\n",
      "1.1032710594641698e-19\n",
      "1.092832859756464e-19\n",
      "1.0529363062822747e-19\n",
      "1.0347494556486445e-19\n",
      "1.0260601110419551e-19\n",
      "9.92851038670354e-20\n",
      "9.777123275262727e-20\n",
      "9.704801736570972e-20\n",
      "9.428366183842613e-20\n",
      "9.302340789180442e-20\n",
      "9.24214072385078e-20\n",
      "9.012047149105608e-20\n",
      "8.907155287422013e-20\n",
      "8.857048597259962e-20\n",
      "8.665501536881089e-20\n",
      "8.578184153210246e-20\n",
      "8.536471842066789e-20\n",
      "8.377053092843121e-20\n",
      "8.304367723027171e-20\n",
      "8.269647150026098e-20\n",
      "8.136935178273226e-20\n",
      "8.076433424528999e-20\n",
      "8.047534485090867e-20\n",
      "7.93706810927917e-20\n",
      "7.886708630992756e-20\n",
      "7.86264974915601e-20\n",
      "7.770697274413045e-20\n",
      "7.728770970810013e-20\n",
      "7.708745432581033e-20\n",
      "7.632208533726729e-20\n",
      "7.597313456794952e-20\n",
      "7.580651421388522e-20\n",
      "7.516936734558202e-20\n",
      "7.48789271117974e-20\n",
      "7.47401851412146e-20\n",
      "7.420978723090539e-20\n",
      "7.396811973421259e-20\n",
      "7.385258599628812e-20\n",
      "7.341121575734406e-20\n",
      "7.320993224822457e-20\n",
      "7.311376940405373e-20\n",
      "7.274625228881189e-20\n",
      "7.257870751339597e-20\n",
      "7.249869998376924e-20\n",
      "7.21928921158177e-20\n",
      "7.205347132670738e-20\n",
      "7.19868619753211e-20\n",
      "7.173223719095524e-20\n",
      "7.161616561435935e-20\n",
      "7.156066392363335e-20\n",
      "7.134881121387622e-20\n",
      "7.125219492095618e-20\n",
      "7.12060497732445e-20\n",
      "7.102953774473798e-20\n",
      "7.094921029028853e-20\n",
      "7.091079668975486e-20\n",
      "7.076394472789088e-20\n",
      "7.069700416429258e-20\n",
      "7.066499281787297e-20\n",
      "7.054276671929758e-20\n",
      "7.048703473496152e-20\n",
      "7.046041429991286e-20\n",
      "7.035870702577426e-20\n",
      "7.031228944820763e-20\n",
      "7.029011492834158e-20\n",
      "7.020543987052987e-20\n",
      "7.016683183538749e-20\n",
      "7.014833098649205e-20\n",
      "7.007787229983383e-20\n",
      "7.004577905673389e-20\n",
      "7.003040202459892e-20\n",
      "6.997181992353126e-20\n",
      "6.994495540007114e-20\n",
      "6.993217722984173e-20\n",
      "6.988336223079648e-20\n",
      "6.986101821087141e-20\n",
      "6.985038004980456e-20\n",
      "6.980977870231467e-20\n",
      "6.979126662841851e-20\n",
      "6.978238879256746e-20\n",
      "6.974854160485763e-20\n",
      "6.973314309653918e-20\n",
      "6.972574402597163e-20\n",
      "6.969762738071626e-20\n",
      "6.968475791104212e-20\n",
      "6.967859683696651e-20\n",
      "6.965517152003994e-20\n",
      "6.964448284710924e-20\n",
      "6.963937725031263e-20\n",
      "6.961985882224868e-20\n",
      "6.96109578062561e-20\n",
      "6.960670514270746e-20\n",
      "6.959045757121869e-20\n",
      "6.958302500025531e-20\n",
      "6.957951265175273e-20\n",
      "6.956590420231289e-20\n",
      "6.955972901616203e-20\n",
      "6.955678474134637e-20\n",
      "6.954553503638469e-20\n",
      "6.95404028835841e-20\n",
      "6.953795094880632e-20\n",
      "6.952865310504983e-20\n",
      "6.95243080967033e-20\n",
      "6.95222666288133e-20\n",
      "6.951451282916877e-20\n",
      "6.951095658079179e-20\n",
      "6.950928566198333e-20\n",
      "6.950271044245599e-20\n",
      "6.949984219038995e-20\n",
      "6.949840085651558e-20\n",
      "6.949299620777292e-20\n",
      "6.949055010161719e-20\n",
      "6.948934623300677e-20\n",
      "6.948487460002495e-20\n",
      "6.948282278710858e-20\n",
      "6.94818154718794e-20\n",
      "6.947810739083385e-20\n",
      "6.947639157874862e-20\n",
      "6.947555701297743e-20\n",
      "6.947246788188862e-20\n",
      "6.94710461039539e-20\n",
      "6.94703395238203e-20\n",
      "6.946773481088641e-20\n",
      "6.946656190605105e-20\n",
      "6.946599715216507e-20\n",
      "6.946385528964315e-20\n",
      "6.946279602080205e-20\n",
      "6.946232655683679e-20\n",
      "6.946058402067168e-20\n",
      "6.945976401075237e-20\n",
      "6.94593729143988e-20\n",
      "6.94579039496058e-20\n",
      "6.945719376157987e-20\n",
      "6.94568680108807e-20\n",
      "6.945561232013388e-20\n",
      "6.945504510219849e-20\n",
      "6.945480102905042e-20\n",
      "6.945370878472955e-20\n",
      "6.9453208213727e-20\n",
      "6.945301018705557e-20\n",
      "6.945212838664686e-20\n",
      "6.945173514197545e-20\n",
      "6.945154660732216e-20\n",
      "6.945088399926916e-20\n",
      "6.945058425506069e-20\n",
      "6.945039959540619e-20\n",
      "6.94497927072675e-20\n",
      "6.944952005817932e-20\n",
      "6.944933419011548e-20\n",
      "6.944889177043521e-20\n",
      "6.94486923695311e-20\n",
      "6.944859313029844e-20\n",
      "6.944809586338356e-20\n",
      "6.944798049782563e-20\n",
      "6.944789083974777e-20\n",
      "6.944752739110079e-20\n",
      "6.944742561390615e-20\n",
      "6.944735057433606e-20\n",
      "6.944709142063498e-20\n",
      "6.944696033350754e-20\n",
      "6.944689765236491e-20\n",
      "6.944662177960204e-20\n",
      "6.944645736974812e-20\n",
      "6.944635884216044e-20\n",
      "6.944624336942913e-20\n",
      "6.94461525632274e-20\n",
      "6.944610936374977e-20\n",
      "6.944590660603605e-20\n",
      "6.944577554507737e-20\n",
      "6.944573968440356e-20\n",
      "6.944566668600953e-20\n",
      "6.944560371986238e-20\n",
      "6.944557361289657e-20\n",
      "6.944545899815242e-20\n",
      "6.944540686750901e-20\n",
      "6.944540973798588e-20\n",
      "6.944531425393219e-20\n",
      "6.94452427542121e-20\n",
      "6.944524960637117e-20\n",
      "6.944514243660042e-20\n",
      "6.944509688588357e-20\n",
      "6.944502423401287e-20\n",
      "6.944495789752838e-20\n",
      "6.944493705285811e-20\n",
      "6.944497820385887e-20\n",
      "6.944494154375465e-20\n",
      "6.944488875108361e-20\n",
      "6.944487677307586e-20\n",
      "6.944477531198025e-20\n",
      "6.944475445529217e-20\n",
      "6.944477229524364e-20\n",
      "6.944481730692891e-20\n",
      "6.944477221249953e-20\n",
      "6.944474547856659e-20\n",
      "6.944471370093205e-20\n",
      "6.944469917965447e-20\n",
      "6.9444720106545e-20\n",
      "6.944466586665008e-20\n",
      "6.944472781831671e-20\n",
      "6.944474981676616e-20\n",
      "6.944456137025807e-20\n",
      "6.944455129744801e-20\n",
      "6.944462978724378e-20\n",
      "6.944453744932685e-20\n",
      "6.944458463172622e-20\n",
      "6.944460834867526e-20\n",
      "6.944455608628977e-20\n",
      "6.944457683975031e-20\n",
      "6.944454574487797e-20\n",
      "6.944453310381953e-20\n",
      "6.94445272932419e-20\n",
      "6.944455226831007e-20\n",
      "6.944445840818895e-20\n",
      "6.944448137163716e-20\n",
      "6.944445130985136e-20\n",
      "6.944444252466491e-20\n",
      "6.944443843121637e-20\n",
      "6.94444365664632e-20\n"
     ]
    }
   ],
   "source": [
    "# Now that we have defined all the methods let´s check what is the result of our optimization problem: \n",
    "\n",
    "initialPointsGuess = [0.1, 0.8, 2, 1.2] # Set of initial points from which we want to find the minimum of the function. \n",
    "\n",
    "# initialPointsGuess = [1, 0.4, 0.3, 0.9] \n",
    "# initialPointsGuess = [-1, 0.4, -0.3, 0.9]  # I have randomly chosen this points and the method works for any of them.  \n",
    "# initialPointsGuess = [-1, -0.4, 0.7, -0.9] \n",
    "\n",
    "\n",
    "tol = 10e-15 # Maximum error value that we want to have. \n",
    "alpha = 0.2 # Value of alpha that we choose. It should be in the bounds (0-1)\n",
    "\n",
    "finalPointsEstimation = gradientDescend(ErrorFunction, np.array(initialPointsGuess), alpha, tol)\n",
    "# This is the result that we obtain by minimizing the proposed function. \n",
    "\n",
    "Achieved_iterations = finalPointsEstimation[1] # Number of iterations computed.\n",
    "GradientDescendSolution = finalPointsEstimation[0] # Value of each of the 4 variables we have optimized. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analitical solution substitued on the Error Function:  4.930380657631324e-32\n",
      "Approximation computed on Gradient Descent substitued on the Error Function:   6.94444365664632e-20\n",
      "\n",
      "Initial points chosen:  [0.1, 0.8, 2, 1.2]\n",
      "Final Points Achieved by Gradient:  [0.5773502690691473 -0.5773502690695417 1.0000000000421623\n",
      " 1.0000000000411708]\n",
      "Number of Iterations computed:  900\n"
     ]
    }
   ],
   "source": [
    "# Let´s check what is the Error we are getting. \n",
    "\n",
    "RealSolutionProvidedByTrapezoidRule = [-1/np.sqrt(3), 1/np.sqrt(3), 1, 1];\n",
    "# This is the analitical solution that I have computed manually. \n",
    "# If we substitute this values on the error function it should return 0. \n",
    "\n",
    "print(\"Analitical solution substitued on the Error Function: \",\n",
    "      ErrorFunction(RealSolutionProvidedByTrapezoidRule[0], RealSolutionProvidedByTrapezoidRule[1], \n",
    "                    RealSolutionProvidedByTrapezoidRule[2], RealSolutionProvidedByTrapezoidRule[3]))\n",
    "\n",
    "\n",
    "print(\"Approximation computed on Gradient Descent substitued on the Error Function:  \", \n",
    "      ErrorFunction(GradientDescendSolution[0], GradientDescendSolution[1], \n",
    "                    GradientDescendSolution[2], GradientDescendSolution[3]))\n",
    "\n",
    "\n",
    "print(\"\\nInitial points chosen: \", initialPointsGuess)\n",
    "print(\"Final Points Achieved by Gradient: \", GradientDescendSolution)\n",
    "print(\"Number of Iterations computed: \", Achieved_iterations)\n",
    "\n",
    "# We can see that the error that we take with our approximation is quite low, to the power of 20, \n",
    "# and the points that we get as solution are also really accurate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real value of the integral:  -8.666676000000008\n",
      "Value of the estimation of the integral using Gradient:  -8.666666665083282\n",
      "The error comitted while computing the integral is:  8.714067027825283e-11\n"
     ]
    }
   ],
   "source": [
    "# To finish, we need to make sure that effectively by minimizing this error function we are really computing \n",
    "# some value for which we can approximate any integral of degree up to 3. Let´s do it: \n",
    "\n",
    "\n",
    "n = 1000 # Number of points we want to take. \n",
    "lowerBound = -1 # Minimum value of the region at which we integrate.\n",
    "upperBound = 1 # Maximum value of the region. \n",
    "t = np.linspace(lowerBound, upperBound, n+1) # time line \n",
    "\n",
    "p = [5*t**3 - 7*t**2 + 6*t - 2] # Function Example to prove we are doing this well. \n",
    "pn = lambda x: 5*x**3 - 7*x**2 + 6*x - 2 # The same function but defined with lambda x. \n",
    "\n",
    "realValueComputedWithTrapezoidRule = computeAListOfIntegrals(lowerBound, upperBound, p, n) \n",
    "# Here I am calling method computeAListOfIntegrals above that makes the integral with Composite Trapezoid Rule\n",
    "# very accurately. \n",
    "\n",
    "\n",
    "print(\"Real value of the integral: \", realValueComputedWithTrapezoidRule[0])\n",
    "\n",
    "approximationComputedWithGradient = estimation([GradientDescendSolution[0], GradientDescendSolution[1]], \n",
    "                 GradientDescendSolution[2], GradientDescendSolution[3], pn)\n",
    "\n",
    "print(\"Value of the estimation of the integral using Gradient: \", approximationComputedWithGradient)\n",
    "\n",
    "errorCommited = (realValueComputedWithTrapezoidRule[0] - approximationComputedWithGradient)**2\n",
    "\n",
    "print(\"The error comitted while computing the integral is: \", errorCommited)\n",
    "\n",
    "# We have to take into account that the method that computes the \"Real\" integral has also a small error, so in fact \n",
    "# this error is small and maybe even our approximation is better than the method we have implemented. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Conclusions**\n",
    "\n",
    "At the end we can see that we are achieving an error in minimizing the Error function of 10e-20, what is a really good solution and 10e-11 while computing any of the integrals. \n",
    "\n",
    "Remark again that what I have done is first obtaining the Composite Trapezoid from the first assignment, then compute the gradient in four variables with finite differences and to finish, minimize the error function with Gradient Descend. \n",
    "\n",
    "I have to say that this assignment has been a bit more difficult than the first one, as it is expected if we take into account that we are in a higher dimension (4 variables) so we cannot even plot the function to obtain the minimum, but it has been challenging to compute each of the steps and I have liked it. \n",
    "\n",
    "I have computed each of the methods personally, by my self, and the same applies with the analytical solution.\n",
    "\n",
    "Also I think that by doing this kind of assignments is the way that we really learn what we are doing, and as you do not have to memorize each function and we have the computer, we can make hard computations and learn to solve difficult problems for the future. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7eb664a86ec4e6d7d42cff77307c7731fb8451b48406edde0b14b746f2e723a6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
